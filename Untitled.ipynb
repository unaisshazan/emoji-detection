{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 09:06:54.928967 13792 deprecation_wrapper.py:119] From C:\\Users\\unais\\Desktop\\ai\\Emojinator-master\\Emojinator_V2\\utils\\label_map_util.py:116: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "W0924 09:06:55.013288 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 09:06:55.014775 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 09:06:55.017753 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 09:06:55.032136 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0924 09:06:55.065369 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0924 09:06:55.073308 13792 deprecation.py:506] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0924 09:06:55.074296 13792 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0924 09:06:55.129370 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0924 09:06:55.218137 13792 deprecation_wrapper.py:119] From D:\\New folder\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0924 09:06:55.367594 13792 deprecation.py:323] From D:\\New folder\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ====== loading HAND frozen graph into memory\n",
      ">  ====== Hand Inference graph loaded.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "1 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "2 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 0.9999858\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "4 1.0\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "4 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "4 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "9 1.0\n",
      "11 1.0\n",
      "9 1.0\n",
      "6 1.0\n",
      "11 1.0\n",
      "9 1.0\n",
      "6 1.0\n",
      "9 1.0\n",
      "3 1.0\n",
      "9 1.0\n",
      "9 1.0\n",
      "11 1.0\n",
      "6 1.0\n",
      "11 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 1.0\n",
      "6 1.0\n",
      "3 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "9 1.0\n",
      "6 1.0\n",
      "6 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "1 1.0\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "6 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "9 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "9 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 1.0\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n",
      "11 0.10973839\n"
     ]
    }
   ],
   "source": [
    "    from utils import detector_utils as detector_utils\n",
    "    import cv2\n",
    "    import tensorflow as tf\n",
    "    import cv2\n",
    "    from keras.models import load_model\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    model = load_model('emojinator.h5')\n",
    "    detection_graph, sess = detector_utils.load_inference_graph()\n",
    "\n",
    "\n",
    "    def keras_predict(model, image):\n",
    "        processed = keras_process_image(image)\n",
    "        pred_probab = model.predict(processed)[0]\n",
    "        pred_class = list(pred_probab).index(max(pred_probab))\n",
    "        return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "    def keras_process_image(img):\n",
    "        image_x = 50\n",
    "        image_y = 50\n",
    "        img = cv2.resize(img, (image_x, image_y))\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "        return img\n",
    "\n",
    "\n",
    "    def get_emojis():\n",
    "        emojis_folder = 'hand_emo/'\n",
    "        emojis = []\n",
    "        for emoji in range(len(os.listdir(emojis_folder))):\n",
    "            print(emoji)\n",
    "            emojis.append(cv2.imread(emojis_folder + str(emoji) + '.png', -1))\n",
    "        return emojis\n",
    "\n",
    "\n",
    "    def overlay(image, emoji, x, y, w, h):\n",
    "        emoji = cv2.resize(emoji, (w, h))\n",
    "        try:\n",
    "            image[y:y + h, x:x + w] = blend_transparent(image[y:y + h, x:x + w], emoji)\n",
    "        except:\n",
    "            pass\n",
    "        return image\n",
    "\n",
    "\n",
    "    def blend_transparent(face_img, overlay_t_img):\n",
    "        # Split out the transparency mask from the colour info\n",
    "        overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "        overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "        # Again calculate the inverse mask\n",
    "        background_mask = 255 - overlay_mask\n",
    "\n",
    "        # Turn the masks into three channel, so we can use them as weights\n",
    "        overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "        background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Create a masked out face image, and masked out overlay\n",
    "        # We convert the images to floating point in range 0.0 - 1.0\n",
    "        face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "        overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "        # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "        return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n",
    "\n",
    "\n",
    "    def main():\n",
    "        emojis = get_emojis()\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 900)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 900)\n",
    "\n",
    "        im_width, im_height = (cap.get(3), cap.get(4))\n",
    "        # max number of hands we want to detect/track\n",
    "        num_hands_detect = 1\n",
    "\n",
    "        cv2.namedWindow('Single-Threaded Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "        while True:\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            ret, image_np = cap.read()\n",
    "            image_np = cv2.flip(image_np, 1)\n",
    "            # image_np = cv2.flip(image_np, 1)\n",
    "            try:\n",
    "                image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "            except:\n",
    "                print(\"Error converting to RGB\")\n",
    "\n",
    "            # Actual detection. Variable boxes contains the bounding box cordinates for hands detected,\n",
    "            # while scores contains the confidence for each of these boxes.\n",
    "            # Hint: If len(boxes) > 1 , you may assume you have found atleast one hand (within your score threshold)\n",
    "\n",
    "            boxes, scores = detector_utils.detect_objects(image_np,\n",
    "                                                          detection_graph, sess)\n",
    "\n",
    "            # draw bounding boxes on frame\n",
    "            img = detector_utils.draw_box_on_image(num_hands_detect, 0.4,\n",
    "                                                   scores, boxes, im_width, im_height,\n",
    "                                                   image_np)\n",
    "            image_np=cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "            res = cv2.bitwise_and(img, img, mask=mask2)\n",
    "            gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "            median = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            kernel_square = np.ones((5, 5), np.uint8)\n",
    "            dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "            opening = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel_square)\n",
    "            ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            newImage = cv2.resize(thresh, (50, 50))\n",
    "            pred_probab, pred_class = keras_predict(model, newImage)\n",
    "            print(pred_class, pred_probab)\n",
    "            image_np = overlay(image_np, emojis[pred_class], 400, 300, 90, 90)\n",
    "\n",
    "            cv2.imshow('Single-Threaded Detection',\n",
    "                       image_np)\n",
    "            cv2.imshow('img', img)\n",
    "\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "\n",
    "    keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
    "    if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
